import json
import pandas as pd
import os
import numpy as np

class ParseXlsxMetadata:
    """
    Converts a specified sheet from the metadata dictionary
    (generated by https://github.com/AustralianBioCommons/gen3-metadata-templates)
    to a JSON file. Also formats and renames the primary and foreign keys into a
    gen3 compatible format.

    Attributes:
        xlsx_path (str): The path to the Excel file containing metadata templates.
        link_suffix (str): A suffix to append to link identifiers, default is 's'.
            e.g. if you name your links as "nodeName_link" you may set this to "_link"
    """

    def __init__(self, xlsx_path: str, link_suffix: str = 's', skip_rows: int = 0):
        self.xlsx_path = xlsx_path
        self.skip_rows = skip_rows
        self.xlsx_data_dict = None
        self.link_suffix = link_suffix

    def parse_metadata_template(self) -> dict:
        """
        Parses an Excel file and converts each sheet into a DataFrame.

        This function reads an Excel file specified by the `xlsx_path` and loads
        each sheet into a dictionary where the keys are the sheet names and the
        values are the DataFrames representing the data in those sheets. The first
        few rows of each DataFrame are removed based on the `skip_rows` attribute.

        Returns:
            dict: A dictionary where each key is a sheet name and each value is a
            DataFrame containing the data from that sheet, with the specified number
            of rows removed.
        """
        # load xlsx file
        pd_dict = pd.read_excel(self.xlsx_path, sheet_name=None)

        # in each pandas data frame in the dict, remove the specified number of rows
        for key in pd_dict.keys():
            if self.skip_rows > 0:
                pd_dict[key] = pd_dict[key].iloc[self.skip_rows:, :]
        
        self.xlsx_data_dict = pd_dict

        return pd_dict

    def get_sheet_names(self) -> list:
        """
        Retrieves the names of all sheets in the Excel file.

        Returns:
            list: A list of sheet names present in the Excel file.
        """
        return list(self.xlsx_data_dict.keys())

    def get_pk_fk_pairs(self, xlsx_data_dict: dict, sheet_name: str) -> tuple:
        """
        Extracts the primary key (PK) and foreign key (FK) column names from a
        specified sheet.

        This method retrieves the first two column names from the given sheet in
        the Excel data dictionary, assuming the first column is the primary key
        and the second column is the foreign key.

        Args:
            xlsx_data_dict (dict): A dictionary where each key is a sheet name and
            each value is a DataFrame.
            sheet_name (str): The name of the sheet from which to extract the PK and FK.

        Returns:
            tuple: A tuple containing the primary key and foreign key column names.
        """
        sheet = xlsx_data_dict[sheet_name]
        first_two_columns = sheet.columns[:2].tolist()
        pk = first_two_columns[0]
        fk = first_two_columns[1]
        return pk, fk

    def pd_to_json(self, xlsx_data_dict: dict, sheet_name: str, json_path: str) -> None:
        """
        Converts a specified sheet from the metadata dictionary to a JSON file.
        Also formats and renames the primary and foreign keys into a gen3 compatible
        format.

        Args:
            xlsx_data_dict (dict): A dictionary where each key is a sheet name and each
            value is a DataFrame.
            sheet_name (str): The name of the sheet to convert to JSON.
            json_path (str): The path to the JSON file to be saved.

        Returns:
            None
        """
        pk, fk = self.get_pk_fk_pairs(xlsx_data_dict, sheet_name)

        df = xlsx_data_dict[sheet_name]
        df = df.replace({np.nan: None, pd.NaT: None})
        df['type'] = sheet_name  # add node / entity name
        fk_name = fk.split('_uid')[0]  # getting foreign key node name

        df['key_fk'] = df[fk].tolist()  # creating var for fk
        df['key_pk'] = df[pk].tolist()  # creating var for pk

        # format foreign key
        df[f"{fk_name}{self.link_suffix}"] = df[fk].apply(lambda x: {"submitter_id": x})
        df_cleaned = df.where(pd.notnull(df), None)  # removing NaN values
        # adding primary key as submitter_id key
        df_cleaned['submitter_id'] = df_cleaned[pk].tolist()
        # removing _uid columns
        df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.str.endswith('_uid')]
        data_list = df_cleaned.to_dict(orient='records')  # converting to dict

        with open(json_path, 'w') as f:
            json.dump(data_list, f)

    def write_dict_to_json(self, xlsx_data_dict: dict, output_dir: str) -> None:
        """
        Writes a dictionary of pandas DataFrames to JSON files.

        Args:
            xlsx_data_dict (dict): The dictionary containing DataFrames to be written to JSON files.
            output_dir (str): The directory where JSON files will be created.

        Returns:
            None
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        for key, value in xlsx_data_dict.items():
            json_path = f"{output_dir}/{key}.json"
            self.pd_to_json(xlsx_data_dict, key, json_path)

        print(f"JSON files written to {output_dir}")